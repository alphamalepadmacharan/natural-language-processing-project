{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /usr/local/lib/python3.11/dist-packages/~vidia*\n"
      ],
      "metadata": {
        "id": "ScY9pIvOxrH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcTF34TTqLJ6",
        "outputId": "2326804f-f130-4e93-e73d-905cf96e526a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.24.4 in /usr/local/lib/python3.11/dist-packages (1.24.4)\n"
          ]
        }
      ],
      "source": [
        "# Downgrade numpy if you want to strictly match\n",
        "!pip install numpy==1.24.4\n",
        "\n",
        "# Then, restart runtime (Menu > Runtime > Restart Runtime) #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29PgQFRqqNME",
        "outputId": "44273f92-52ba-4e07-d37c-266790b9c227"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.24.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Collecting git+https://github.com/facebookresearch/fastText.git\n",
            "  Cloning https://github.com/facebookresearch/fastText.git to /tmp/pip-req-build-ecuc4yj4\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/fastText.git /tmp/pip-req-build-ecuc4yj4\n",
            "  Resolved https://github.com/facebookresearch/fastText.git to commit 1142dc4c4ecbc19cc16eee5cdd28472e689267e6\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.11/dist-packages (from fasttext==0.9.2) (2.13.6)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from fasttext==0.9.2) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fasttext==0.9.2) (1.24.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade gensim\n",
        "!pip install git+https://github.com/facebookresearch/fastText.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "MYY9Z3FCDNXW",
        "outputId": "c1d48776-b5b6-4e1d-9422-006204912eae"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f4dc56df-1453-44b2-86a5-505f061de5f4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f4dc56df-1453-44b2-86a5-505f061de5f4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-5c2e8a8d365b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    165\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    166\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_T6YcLNDGJ7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "os.rename('kaggle.json', '/root/.kaggle/kaggle.json')\n",
        "os.chmod('/root/.kaggle/kaggle.json', 600)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxtMtCorDVWj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fff3dd7c-9d34-4862-a3a8-ef7c7d6b6539"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/manidaaw/tamil-oscar-corpus\n",
            "License(s): unknown\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d manidaaw/tamil-oscar-corpus\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhZnCg7gDduN"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"tamil-oscar-corpus.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"tamil_oscar\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "saHFdVyIHhCa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08046de8-f095-4ef9-b341-b928ca03c382"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sentences loaded: 2470684\n",
            "Sample: ['à®’à®²à®¿à®®à¯à®ªà®¿à®•à¯', 'à®ªà¯‹à®Ÿà¯à®Ÿà®¿à®•à®³à¯', 'à®¨à®Ÿà®¨à¯à®¤', 'à®‡à®Ÿà®™à¯à®•à®³à¯', '1.', '1896', '-', 'à®à®¤à¯†à®©à¯à®¸à¯,', 'à®•à®¿à®°à¯€à®¸à¯', '2.', '1900', '-', 'à®ªà®¾à®°à®¿à®¸à¯,', 'à®ªà®¿à®°à®¾à®©à¯à®¸à¯', '3.', '1904', '-', 'à®šà¯†à®¯à®¿à®©à¯', 'à®²à¯‚à®¯à®¿à®¸à¯,', 'à®…à®®à¯†à®°à®¿à®•à¯à®•à®¾', '4.', '1908', '-', 'à®²à®£à¯à®Ÿà®©à¯,à®ªà®¿à®°à®¿à®Ÿà¯à®Ÿà®©à¯', '5.', '1912', '-', 'à®¸à¯à®Ÿà¯‹à®•à¯à®¹à¯‹à®®à¯,', 'à®šà¯à®µà¯€à®Ÿà®©à¯', '6.', '1920', '-', 'à®†à®£à¯à®Ÿà¯à®µà¯†à®°à¯à®ªà¯,', 'à®ªà¯†à®²à¯à®œà®¿à®¯à®®à¯', '7.', '1924', '-', 'à®ªà®¾à®°à®¿à®¸à¯,', 'à®ªà®¿à®°à®¾à®©à¯à®¸à¯', '8.', '1928', '-', 'à®†à®®à¯à®¸à¯à®Ÿà®°à¯à®Ÿà®¾à®®à¯,', 'à®¹à®¾à®²à®¨à¯à®¤à¯', '9.', '1932', '-', 'à®²à®¾à®¸à¯,', 'à®à®à¯à®šà®²à¯à®¸à¯', '10.', '1936', '-', 'à®ªà¯†à®°à¯à®²à®¿à®©à¯,', 'à®œà¯†à®°à¯à®®à®©à®¿', '11.', '1948', '-', 'à®²à®£à¯à®Ÿà®©à¯,', 'à®‡à®™à¯à®•à®¿à®²à®¾à®¨à¯à®¤à¯', '12.', '1952', '-', 'à®¹à®²à¯à®šà®¿à®©à¯à®•à®¿,', 'à®ªà®¿à®©à¯à®²à®¾à®¨à¯à®¤à¯', '13.', '1956', '-', 'à®®à¯‡à®ªà¯‹à®°à¯à®©à¯,à®†à®¸à¯à®¤à®¿à®°à¯‡à®²à®¿à®¯à®¾', '14.', '1960', '-', 'à®°à¯‹à®®à¯,', 'à®‡à®¤à¯à®¤à®¾à®²à®¿', '15.', '1964', '-', 'à®Ÿà¯‹à®•à¯à®•à®¿à®¯à¯‹,', 'à®œà®ªà¯à®ªà®¾à®©à¯', '16.', '1968', '-', 'à®®à¯†à®•à¯à®šà®¿à®•à¯‹,', 'à®®à¯†à®•à¯à®¸à®¿à®•à¯à®•à¯‹', '17.', '1972', '-', 'à®®à®¿à®¯à¯‚à®©à®¿à®•à¯,', 'à®œà¯†à®°à¯à®®à®©à®¿', '18.', '1976', '-', 'à®®à®¾à®©à¯à®Ÿà¯à®°à®¿à®¯à®²à¯,', 'à®•à®©à®Ÿà®¾', '19.', '1980', '-', 'à®®à®¾à®¸à¯à®•à¯‹,', 'USSR', '20.', '1984', '-', 'à®²à®¾à®¸à¯', 'à®à®à¯à®šà®²à¯à®¸à¯,', 'à®…à®®à¯†à®°à®¿à®•à¯à®•à®¾', '21.', '1988', '-', 'à®šà®¿à®¯à¯‹à®²à¯,', 'à®¤à¯†à®©à¯', 'à®•à¯Šà®°à®¿à®¯à®¾', '22.', '1992', '-', 'à®ªà®¾à®°à¯à®šà®¿à®²à¯‹à®©à®¾,', 'à®¸à¯à®ªà¯†à®¯à®¿à®©à¯', '23.', '1996', '-', 'à®…à®Ÿà¯à®²à®¾à®£à¯à®Ÿà®¾,', 'à®…à®®à¯†à®°à®¿à®•à¯à®•à®¾', '24.', '2000', '-', 'à®šà®¿à®Ÿà¯à®©à®¿,', 'à®†à®¸à¯à®¤à®¿à®°à¯‡à®²à®¿à®¯à®¾', '25.', '2004', '-', 'à®à®¤à¯†à®©à¯à®¸à¯,', 'à®•à®¿à®°à¯€à®¸à¯', '26.', '2008', '-', 'à®ªà¯€à®œà®¿à®™à¯,', 'à®šà¯€à®©à®¾', '27.', '2012', '-', 'à®²à®£à¯à®Ÿà®©à¯,', 'à®‡à®™à¯à®•à®¿à®²à®¾à®¨à¯à®¤à¯', '28.', '2016', '-', 'à®°à®¿à®¯à¯‹,', 'à®ªà®¿à®°à¯‡à®šà®¿à®²à¯', '29.', '2020', '-', 'à®Ÿà¯‹à®•à¯à®•à®¿à®¯à¯‹,', 'à®œà®ªà¯à®ªà®¾à®©à¯', '30.', '2024', '-', 'à®ªà®¾à®°à®¿à®¸à¯,', 'à®ªà®¿à®°à®¾à®©à¯à®¸à¯', '31.', '2028', '-', 'à®²à®¾à®¸à¯', 'à®à®à¯à®šà®²à¯à®¸à¯,', 'à®…à®®à¯†à®°à®¿à®•à¯à®•à®¾', 'Music', 'ncs:', 'https://www.youtube.com/channel/UC_aEa8K-EOJ3D6gOs7HcyNg']\n"
          ]
        }
      ],
      "source": [
        "def read_corpus(path):\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if line:\n",
        "                yield line.split()\n",
        "corpus_path = \"/content/tamil_oscar/ta_part_1.txt.gz\"\n",
        "sentences = list(read_corpus(corpus_path))\n",
        "print(\"Number of sentences loaded:\", len(sentences))\n",
        "print(\"Sample:\", sentences[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OV782AVA0OT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02225e37-88ad-4338-faba-a425c1a9edc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Quick Word2Vec model trained and saved!\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Use a smaller subset for quicker training (adjust as needed)\n",
        "short_sentences = sentences[:50000]  # Only use first 10,000 lines\n",
        "\n",
        "# Train with faster settings\n",
        "w2v_model = Word2Vec(\n",
        "    sentences=short_sentences,\n",
        "    vector_size=50,     # Smaller embedding size\n",
        "    window=5,           # Context window\n",
        "    min_count=10,       # Ignore rare words\n",
        "    workers=4,          # Parallel training\n",
        "    sg=0,               # Use CBOW (faster than skip-gram)\n",
        "    epochs=5            # Fewer training iterations\n",
        ")\n",
        "\n",
        "# Save the model\n",
        "w2v_model.save(\"tamil_word2vec_quick.model\")\n",
        "\n",
        "print(\"âœ… Quick Word2Vec model trained and saved!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpwcXybWJP3h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "659f36bf-b778-4d36-b4ce-74380f4ca03d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“ Vector for à®¤à®®à®¿à®´à¯: [ 0.10792143 -0.24503167 -1.2529924  -0.37729755  1.2537847   2.1221123\n",
            "  0.5669657  -0.2654165  -0.09773123  2.2463973 ]\n",
            "ğŸ” Similar words to 'à®¤à®®à®¿à®´à¯':\n",
            "à®‡à®²à®•à¯à®•à®¿à®¯ - 0.7994\n",
            "à®®à¯Šà®´à®¿ - 0.7944\n",
            "à®šà®¿à®©à®¿à®®à®¾à®µà®¿à®²à¯ - 0.7787\n",
            "à®šà®¿à®©à®¿à®®à®¾ - 0.7655\n",
            "à®šà®¿à®©à®¿à®®à®¾à®µà®¿à®©à¯ - 0.7070\n"
          ]
        }
      ],
      "source": [
        "# Load the model (optional if you're continuing in the same session)\n",
        "from gensim.models import Word2Vec\n",
        "model = Word2Vec.load(\"tamil_word2vec_quick.model\")\n",
        "\n",
        "# Get vector for a word\n",
        "print(\"ğŸ“ Vector for à®¤à®®à®¿à®´à¯:\", model.wv[\"à®¤à®®à®¿à®´à¯\"][:10])  # First 10 dimensions\n",
        "\n",
        "# Find most similar words\n",
        "similar_words = model.wv.most_similar(\"à®¤à®®à®¿à®´à¯\", topn=5)\n",
        "print(\"ğŸ” Similar words to 'à®¤à®®à®¿à®´à¯':\")\n",
        "for word, score in similar_words:\n",
        "    print(f\"{word} - {score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ByuEeyEJsKD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a15bd49-b285-47b2-c2ed-b04d0b24ef3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœï¸ Enter a Tamil sentence: à®¤à®®à®¿à®´à¯ à®’à®°à¯ à®…à®´à®•à®¾à®© à®®à¯Šà®´à®¿.\n",
            "\n",
            "ğŸ” Word analysis:\n",
            "\n",
            "ğŸ“Œ Word: à®¤à®®à®¿à®´à¯\n",
            "ğŸ”¹ Vector (first 5 dims): [ 0.10792143 -0.24503167 -1.2529924  -0.37729755  1.2537847 ]\n",
            "ğŸ”— Top 3 similar words:\n",
            "   â¤ à®‡à®²à®•à¯à®•à®¿à®¯ (0.7994)\n",
            "   â¤ à®®à¯Šà®´à®¿ (0.7944)\n",
            "   â¤ à®šà®¿à®©à®¿à®®à®¾à®µà®¿à®²à¯ (0.7787)\n",
            "\n",
            "ğŸ“Œ Word: à®’à®°à¯\n",
            "ğŸ”¹ Vector (first 5 dims): [-0.2968386   1.3143142  -0.46690714  1.3146205  -1.2328315 ]\n",
            "ğŸ”— Top 3 similar words:\n",
            "   â¤ à®’à®°à¯‡ (0.7826)\n",
            "   â¤ à®‡à®©à¯à®©à¯Šà®°à¯ (0.7039)\n",
            "   â¤ à®…à®¤à¯‡ (0.7025)\n",
            "\n",
            "ğŸ“Œ Word: à®…à®´à®•à®¾à®©\n",
            "ğŸ”¹ Vector (first 5 dims): [-0.15006211  0.7148199  -0.62346435  0.19145738 -0.64105445]\n",
            "ğŸ”— Top 3 similar words:\n",
            "   â¤ à®ªà®•à¯à®•à®®à¯ (0.9705)\n",
            "   â¤ à®•à¯à®°à®²à®¿à®²à¯ (0.9636)\n",
            "   â¤ à®ªà®¿à®Ÿà®¿à®¤à¯à®¤ (0.9603)\n",
            "\n",
            "ğŸ“Œ Word: à®®à¯Šà®´à®¿.\n",
            "ğŸ”¹ Vector (first 5 dims): [ 0.06857381  0.13303326 -0.19101429 -0.0338296  -0.00205726]\n",
            "ğŸ”— Top 3 similar words:\n",
            "   â¤ à®®à¯Šà®´à®¿, (0.9735)\n",
            "   â¤ à®ªà®Ÿà¯ˆà®ªà¯à®ªà¯à®•à®³à¯ (0.9713)\n",
            "   â¤ à®®à¯Šà®´à®¿à®¯à®¿à®©à¯ (0.9672)\n"
          ]
        }
      ],
      "source": [
        "# ğŸ’¬ Input a Tamil sentence from the user\n",
        "input_sentence = input(\"âœï¸ Enter a Tamil sentence: \")\n",
        "\n",
        "# ğŸ§© Tokenize the sentence (basic whitespace-based split)\n",
        "words = input_sentence.strip().split()\n",
        "\n",
        "print(\"\\nğŸ” Word analysis:\")\n",
        "for word in words:\n",
        "    if word in model.wv:\n",
        "        print(f\"\\nğŸ“Œ Word: {word}\")\n",
        "        print(\"ğŸ”¹ Vector (first 5 dims):\", model.wv[word][:5])\n",
        "\n",
        "        similar_words = model.wv.most_similar(word, topn=3)\n",
        "        print(\"ğŸ”— Top 3 similar words:\")\n",
        "        for similar_word, score in similar_words:\n",
        "            print(f\"   â¤ {similar_word} ({score:.4f})\")\n",
        "    else:\n",
        "        print(f\"\\nâš ï¸ Word '{word}' not found in vocabulary.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3zlWvW8l05v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "683309e9-e6eb-45c6-e655-c77a45b90501"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.45.0-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.24.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.37.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "Downloading streamlit-1.45.0-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.45.0 watchdog-6.0.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  fonts-noto-cjk fonts-noto-cjk-extra fonts-noto-color-emoji fonts-noto-core\n",
            "  fonts-noto-extra fonts-noto-mono fonts-noto-ui-core fonts-noto-ui-extra\n",
            "  fonts-noto-unhinted\n",
            "The following NEW packages will be installed:\n",
            "  fonts-noto fonts-noto-cjk fonts-noto-cjk-extra fonts-noto-color-emoji\n",
            "  fonts-noto-core fonts-noto-extra fonts-noto-mono fonts-noto-ui-core\n",
            "  fonts-noto-ui-extra fonts-noto-unhinted\n",
            "0 upgraded, 10 newly installed, 0 to remove and 34 not upgraded.\n",
            "Need to get 317 MB of archives.\n",
            "After this operation, 790 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-noto-core all 20201225-1build1 [12.2 MB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-noto all 20201225-1build1 [16.8 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-noto-cjk all 1:20220127+repack1-1 [61.2 MB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-noto-cjk-extra all 1:20220127+repack1-1 [145 MB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 fonts-noto-color-emoji all 2.047-0ubuntu0.22.04.1 [10.0 MB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-noto-extra all 20201225-1build1 [72.4 MB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-noto-mono all 20201225-1build1 [397 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-noto-ui-core all 20201225-1build1 [1,420 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-noto-ui-extra all 20201225-1build1 [14.3 MB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-noto-unhinted all 20201225-1build1 [16.8 kB]\n",
            "Fetched 317 MB in 35s (9,056 kB/s)\n",
            "Selecting previously unselected package fonts-noto-core.\n",
            "(Reading database ... 126102 files and directories currently installed.)\n",
            "Preparing to unpack .../0-fonts-noto-core_20201225-1build1_all.deb ...\n",
            "Unpacking fonts-noto-core (20201225-1build1) ...\n",
            "Selecting previously unselected package fonts-noto.\n",
            "Preparing to unpack .../1-fonts-noto_20201225-1build1_all.deb ...\n",
            "Unpacking fonts-noto (20201225-1build1) ...\n",
            "Selecting previously unselected package fonts-noto-cjk.\n",
            "Preparing to unpack .../2-fonts-noto-cjk_1%3a20220127+repack1-1_all.deb ...\n",
            "Unpacking fonts-noto-cjk (1:20220127+repack1-1) ...\n",
            "Selecting previously unselected package fonts-noto-cjk-extra.\n",
            "Preparing to unpack .../3-fonts-noto-cjk-extra_1%3a20220127+repack1-1_all.deb ...\n",
            "Unpacking fonts-noto-cjk-extra (1:20220127+repack1-1) ...\n",
            "Selecting previously unselected package fonts-noto-color-emoji.\n",
            "Preparing to unpack .../4-fonts-noto-color-emoji_2.047-0ubuntu0.22.04.1_all.deb ...\n",
            "Unpacking fonts-noto-color-emoji (2.047-0ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package fonts-noto-extra.\n",
            "Preparing to unpack .../5-fonts-noto-extra_20201225-1build1_all.deb ...\n",
            "Unpacking fonts-noto-extra (20201225-1build1) ...\n",
            "Selecting previously unselected package fonts-noto-mono.\n",
            "Preparing to unpack .../6-fonts-noto-mono_20201225-1build1_all.deb ...\n",
            "Unpacking fonts-noto-mono (20201225-1build1) ...\n",
            "Selecting previously unselected package fonts-noto-ui-core.\n",
            "Preparing to unpack .../7-fonts-noto-ui-core_20201225-1build1_all.deb ...\n",
            "Unpacking fonts-noto-ui-core (20201225-1build1) ...\n",
            "Selecting previously unselected package fonts-noto-ui-extra.\n",
            "Preparing to unpack .../8-fonts-noto-ui-extra_20201225-1build1_all.deb ...\n",
            "Unpacking fonts-noto-ui-extra (20201225-1build1) ...\n",
            "Selecting previously unselected package fonts-noto-unhinted.\n",
            "Preparing to unpack .../9-fonts-noto-unhinted_20201225-1build1_all.deb ...\n",
            "Unpacking fonts-noto-unhinted (20201225-1build1) ...\n",
            "Setting up fonts-noto-mono (20201225-1build1) ...\n",
            "Setting up fonts-noto-color-emoji (2.047-0ubuntu0.22.04.1) ...\n",
            "Setting up fonts-noto-ui-extra (20201225-1build1) ...\n",
            "Setting up fonts-noto-extra (20201225-1build1) ...\n",
            "Setting up fonts-noto-cjk (1:20220127+repack1-1) ...\n",
            "Setting up fonts-noto-unhinted (20201225-1build1) ...\n",
            "Setting up fonts-noto-ui-core (20201225-1build1) ...\n",
            "Setting up fonts-noto-core (20201225-1build1) ...\n",
            "Setting up fonts-noto-cjk-extra (1:20220127+repack1-1) ...\n",
            "Setting up fonts-noto (20201225-1build1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit matplotlib\n",
        "!apt-get -y install fonts-noto\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Tamil font\n",
        "!apt-get -y install fonts-noto\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['font.family'] = 'Noto Sans Tamil'\n",
        "plt.rcParams['axes.unicode_minus'] = False\n"
      ],
      "metadata": {
        "id": "YdOXSR9Szx0w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "303c52e7-21de-42ba-eb25-0b3d5e723bc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "fonts-noto is already the newest version (20201225-1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aax-053xpA1Z"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_similar_words(word):\n",
        "    if word not in model.wv:\n",
        "        return f\"âš ï¸ '{word}' not found in vocabulary.\", None\n",
        "\n",
        "    similar = model.wv.most_similar(word, topn=5)\n",
        "    labels, scores = zip(*similar)\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.barh(labels, scores)\n",
        "    plt.xlabel(\"Similarity Score\")\n",
        "    plt.title(f\"Top 5 Similar Words to '{word}'\")\n",
        "    plt.gca().invert_yaxis()\n",
        "\n",
        "    return f\"ğŸ” Similar words to '{word}'\", plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "\n",
        "# Use Noto Sans Tamil font for Tamil rendering\n",
        "plt.rcParams['font.family'] = 'Noto Sans Tamil'\n"
      ],
      "metadata": {
        "id": "ncDJ0FLeJ0jj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get -y install fonts-noto fonts-noto-unhinted fonts-noto-color-emoji\n"
      ],
      "metadata": {
        "id": "7jVuokHYJ4ew",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d32c4f6-c4d4-4cbe-a953-4541ed9e9021"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "fonts-noto is already the newest version (20201225-1build1).\n",
            "fonts-noto-unhinted is already the newest version (20201225-1build1).\n",
            "fonts-noto-unhinted set to manually installed.\n",
            "fonts-noto-color-emoji is already the newest version (2.047-0ubuntu0.22.04.1).\n",
            "fonts-noto-color-emoji set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get -y install fonts-noto fonts-noto-unhinted fonts-noto-color-emoji\n"
      ],
      "metadata": {
        "id": "PkCIlNEQJ646",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa493d5d-65e5-4221-dce6-9456711c9f04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,723 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,245 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,901 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,211 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,931 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,546 kB]\n",
            "Fetched 21.0 MB in 8s (2,566 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "fonts-noto is already the newest version (20201225-1build1).\n",
            "fonts-noto-unhinted is already the newest version (20201225-1build1).\n",
            "fonts-noto-color-emoji is already the newest version (2.047-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "\n",
        "# Set Tamil font from system path (Linux path)\n",
        "tamil_font = fm.FontProperties(fname=\"/usr/share/fonts/truetype/noto/NotoSansTamil-Regular.ttf\")\n",
        "plt.rcParams['font.family'] = tamil_font.get_name()\n"
      ],
      "metadata": {
        "id": "37ud9TOfLFiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit numpy==1.24.4 gensim git+https://github.com/facebookresearch/fastText.git\n",
        "!apt-get -y install fonts-noto\n"
      ],
      "metadata": {
        "id": "X5MOCRmGI4sB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c80965e-5ec8-4580-cf93-aa0f0499076c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/facebookresearch/fastText.git\n",
            "  Cloning https://github.com/facebookresearch/fastText.git to /tmp/pip-req-build-rhx3lknm\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/fastText.git /tmp/pip-req-build-rhx3lknm\n",
            "  Resolved https://github.com/facebookresearch/fastText.git to commit 1142dc4c4ecbc19cc16eee5cdd28472e689267e6\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.45.0)\n",
            "Requirement already satisfied: numpy==1.24.4 in /usr/local/lib/python3.11/dist-packages (1.24.4)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.11/dist-packages (from fasttext==0.9.2) (2.13.6)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from fasttext==0.9.2) (75.2.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.37.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.4.26)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "fonts-noto is already the newest version (20201225-1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "\n",
        "# âœ… Tamil Font Handling (Linux + Windows fallback)\n",
        "try:\n",
        "    tamil_font = fm.FontProperties(fname=\"/usr/share/fonts/truetype/noto/NotoSansTamil-Regular.ttf\")  # Linux path\n",
        "except:\n",
        "    tamil_font = fm.FontProperties(fname=\"C:/Windows/Fonts/NotoSansTamil-Regular.ttf\")  # Windows path\n",
        "\n",
        "plt.rcParams['font.family'] = tamil_font.get_name()\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# âœ… Load Word2Vec model\n",
        "model = Word2Vec.load(\"tamil_word2vec_quick.model\")\n",
        "\n",
        "# âœ… Sample intent dataset\n",
        "intent_data = [\n",
        "    (\"à®µà®£à®•à¯à®•à®®à¯, à®à®ªà¯à®ªà®Ÿà®¿ à®‡à®°à¯à®•à¯à®•à®¿à®±à¯€à®°à¯à®•à®³à¯?\", \"à®µà®¾à®´à¯à®¤à¯à®¤à¯\"),\n",
        "    (\"à®Ÿà®¿à®•à¯à®•à¯†à®Ÿà¯ à®ªà®¤à®¿à®µà¯ à®šà¯†à®¯à¯à®¯à®µà¯‡à®£à¯à®Ÿà¯à®®à¯\", \"à®Ÿà®¿à®•à¯à®•à¯†à®Ÿà¯ à®ªà®¤à®¿à®µà¯\"),\n",
        "    (\"à®’à®°à¯ à®ªà®Ÿà®®à¯ à®ªà®¾à®°à¯à®•à¯à®•à®µà¯‡à®£à¯à®Ÿà¯à®®à¯\", \"à®ªà¯Šà®´à¯à®¤à¯ à®µà®¿à®©à¯‹à®¤à®®à¯\"),\n",
        "    (\"à®à®©à®¤à¯ à®Ÿà®¿à®•à¯à®•à¯†à®Ÿà¯à®Ÿà¯ˆ à®°à®¤à¯à®¤à¯ à®šà¯†à®¯à¯à®¯à®µà¯à®®à¯\", \"à®Ÿà®¿à®•à¯à®•à¯†à®Ÿà¯ à®°à®¤à¯à®¤à¯\"),\n",
        "    (\"à®¨à®©à¯à®±à®¿ à®‰à®™à¯à®•à®³à¯ à®‰à®¤à®µà®¿à®•à¯à®•à¯\", \"à®¨à®©à¯à®±à®¿\"),\n",
        "    (\"à®®à®¾à®²à¯ˆ à®·à¯‹à®•à¯à®•à¯ à®Ÿà®¿à®•à¯à®•à¯†à®Ÿà¯ à®µà¯‡à®£à¯à®Ÿà¯à®®à¯\", \"à®Ÿà®¿à®•à¯à®•à¯†à®Ÿà¯ à®ªà®¤à®¿à®µà¯\"),\n",
        "    (\"à®à®©à®¤à¯ à®Ÿà®¿à®•à¯à®•à¯†à®Ÿà¯à®Ÿà¯ˆ à®®à¯à®Ÿà®•à¯à®•à®¿à®¯à¯à®™à¯à®•à®³à¯\", \"à®Ÿà®¿à®•à¯à®•à¯†à®Ÿà¯ à®°à®¤à¯à®¤à¯\"),\n",
        "    (\"à®‰à®™à¯à®•à®³à¯ à®šà¯‡à®µà¯ˆà®•à¯à®•à¯ à®¨à®©à¯à®±à®¿\", \"à®¨à®©à¯à®±à®¿\"),\n",
        "    (\"à®¨à®¾à®©à¯ à®ªà®Ÿà®®à¯ à®ªà®¾à®°à¯à®•à¯à®• à®µà®¿à®°à¯à®®à¯à®ªà¯à®•à®¿à®±à¯‡à®©à¯\", \"à®ªà¯Šà®´à¯à®¤à¯ à®µà®¿à®©à¯‹à®¤à®®à¯\"),\n",
        "    (\"à®µà®£à®•à¯à®•à®®à¯\", \"à®µà®¾à®´à¯à®¤à¯à®¤à¯\")\n",
        "]\n",
        "\n",
        "# âœ… Vectorizer\n",
        "def get_sentence_vector(sentence):\n",
        "    words = sentence.strip().split()\n",
        "    vectors = [model.wv[word] for word in words if word in model.wv]\n",
        "    return np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)\n",
        "\n",
        "# âœ… Train classifier\n",
        "X = [get_sentence_vector(text) for text, label in intent_data]\n",
        "y = [label for _, label in intent_data]\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X, y_encoded)\n",
        "\n",
        "# âœ… Streamlit UI\n",
        "st.title(\"Word embedding for tamil language(à®¤à®®à®¿à®´à¯ à®®à¯Šà®´à®¿à®•à¯à®•à®¾à®© à®µà®¾à®°à¯à®¤à¯à®¤à¯ˆ à®‰à®Ÿà¯à®ªà¯Šà®¤à®¿à®¤à¯à®¤à®²à¯)\")\n",
        "st.markdown(\"à®¤à®®à®¿à®´à¯ à®‰à®°à¯ˆà®¯à¯ˆ à®‰à®³à¯à®³à®¿à®Ÿà®µà¯à®®à¯ â€“ à®¨à®¾à®™à¯à®•à®³à¯ à®¨à¯‹à®•à¯à®•à®®à¯ à®®à®±à¯à®±à¯à®®à¯ à®‡à®£à¯ˆà®¯à®¾à®© à®šà¯Šà®±à¯à®•à®³à¯ˆ à®•à®¾à®Ÿà¯à®Ÿà¯à®µà¯‹à®®à¯:\")\n",
        "\n",
        "user_input = st.text_input(\"âœï¸ à®‰à®™à¯à®•à®³à¯ à®µà®¾à®•à¯à®•à®¿à®¯à®¤à¯à®¤à¯ˆ à®‰à®³à¯à®³à®¿à®Ÿà®µà¯à®®à¯\")\n",
        "\n",
        "if user_input:\n",
        "    vec = get_sentence_vector(user_input)\n",
        "    pred = clf.predict([vec])[0]\n",
        "    pred_label = le.inverse_transform([pred])[0]\n",
        "    st.success(f\"**à®•à®£à®¿à®•à¯à®•à®ªà¯à®ªà®Ÿà¯à®Ÿ à®¨à¯‹à®•à¯à®•à®®à¯:** {pred_label}\")\n",
        "\n",
        "    words = user_input.strip().split()\n",
        "    for word in words:\n",
        "        if word in model.wv:\n",
        "            st.markdown(f\"### ğŸ“Œ à®šà¯Šà®²à¯: {word}\")\n",
        "            st.write(\"ğŸ”¹ à®µà¯†à®•à¯à®Ÿà®¾à®°à¯ (à®®à¯à®¤à®²à¯ 5 à®…à®®à¯à®šà®™à¯à®•à®³à¯):\", model.wv[word][:5])\n",
        "            similar = model.wv.most_similar(word, topn=5)\n",
        "            labels, scores = zip(*similar)\n",
        "\n",
        "            # âœ… Tamil-compatible plot\n",
        "            fig, ax = plt.subplots()\n",
        "            ax.barh(labels, scores)\n",
        "            ax.set_xlabel(\"à®’à®±à¯à®±à¯à®®à¯ˆ à®®à®¤à®¿à®ªà¯à®ªà¯†à®£à¯\", fontproperties=tamil_font)\n",
        "            ax.set_title(f\"ğŸ”— '{word}' à®à®©à¯à®ªà®¤à®±à¯à®•à¯ à®‡à®£à¯ˆà®¯à®¾à®© à®šà¯Šà®±à¯à®•à®³à¯\", fontproperties=tamil_font)\n",
        "            ax.invert_yaxis()\n",
        "            for label in ax.get_yticklabels():\n",
        "                label.set_fontproperties(tamil_font)\n",
        "            st.pyplot(fig)\n",
        "        else:\n",
        "            st.warning(f\"âš ï¸ '{word}' à®à®©à¯à®± à®šà¯Šà®²à¯ à®šà¯Šà®²à¯à®²à®•à®°à®¾à®¤à®¿à®¯à®¿à®²à¯ à®‡à®²à¯à®²à¯ˆ.\")\n"
      ],
      "metadata": {
        "id": "ay9BSUusI9bk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49312145-9041-4055-da6a-c9fa0d30c95a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJ57e-imXpMq",
        "outputId": "f1790d91-d6a0-4fcb-fc64-802c32716606"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.8)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import conf, ngrok\n",
        "\n",
        "# Paste your token inside the quotes\n",
        "conf.get_default().auth_token = \"2wawCEdTws3SUlBjgprxu4mTwLZ_jHzbLoc794PdtvaDaGYu\"\n",
        "\n",
        "# Kill any old tunnels\n",
        "ngrok.kill()\n",
        "\n",
        "# Run the Streamlit app\n",
        "!streamlit run app.py &>/content/log.txt &\n",
        "\n",
        "# Create tunnel\n",
        "public_url = ngrok.connect(8501, \"http\")\n",
        "print(f\"ğŸ”— Click here to open your app: {public_url}\")\n"
      ],
      "metadata": {
        "id": "BCOFaGxqJB3B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26752dab-a0e9-4303-ace2-d4ff989ed7cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ”— Click here to open your app: NgrokTunnel: \"https://d39d-130-211-248-205.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}